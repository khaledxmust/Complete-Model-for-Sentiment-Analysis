{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import nltk\n",
    "import pandas as pd\n",
    "from sklearn import svm\n",
    "from sklearn import metrics\n",
    "from sklearn import naive_bayes\n",
    "from gensim.models import KeyedVectors\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-warning\">\n",
    "    1. Reading & PreProcessing Training & Testing Data\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16041\n"
     ]
    }
   ],
   "source": [
    "model = KeyedVectors.load_word2vec_format('GoogleNews-vectors-negative300.bin', binary=True)\n",
    "li = []\n",
    "Cols = ['ID','Label', 'Tweet']\n",
    "path = r'C:\\\\Users\\\\khled\\\\Downloads\\\\Model\\\\'\n",
    "all_files = glob.glob(path + \"/twitter-201*.txt\")\n",
    "#Reading all files:\n",
    "for file in all_files:\n",
    "    df = pd.read_csv(file, names=Cols, delimiter='\\t')\n",
    "    li.append(df)\n",
    "\n",
    "DF = pd.concat(li, axis=0, ignore_index=True)\n",
    "Data = DF.drop('ID', axis=1)\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "\n",
    "porter = PorterStemmer()\n",
    "stop = stopwords.words('english')\n",
    "Data['Tweet'] = Data['Tweet'].replace({r'\\\\':'',r'\\'':'',r'\\,':'','&':'',r'\\\"':'','!':'','\\.':'','u2019':'\\'','u002c':',','(@[A-Za-z0-9]+)|(\\w+:\\/\\/\\S+)':''}, regex=True)\n",
    "Data['Tweet'] = [ tweet.casefold() for tweet in Data['Tweet'] ]\n",
    "Data['Tweet'] = Data['Tweet'].apply(lambda x: ' '.join([word for word in x.split() if word not in (stop)]))\n",
    "Data['Tweet'] = Data['Tweet'].apply(lambda x: ' '.join([porter.stem(word) for word in x.split()]))\n",
    "def cond(i):\n",
    "    if     i == 0: return 'neutral'\n",
    "    elif   i == 1: return 'positive'\n",
    "    elif   i == 2: return 'negative'\n",
    "    return i\n",
    "#Reading Test and Test Labels for evaluating results\n",
    "Test = pd.read_csv(\"C:\\\\Users\\\\khled\\\\Downloads\\\\Model\\\\test.csv\")\n",
    "test_labels = pd.read_csv(\"C:\\\\Users\\\\khled\\\\Downloads\\\\Model\\\\answer_key.csv\")\n",
    "test_labels['vlabels'] = [cond(label) for label in test_labels['label']]\n",
    "Test['tweet'] = Test['tweet'].replace({r'\\\\':'',r'\\'':'',r'\\,':'','&':'',r'\\\"':'','!':'','\\.':'','u2019':'\\'','u002c':',','(@[A-Za-z0-9]+)|(\\w+:\\/\\/\\S+)':''}, regex=True)\n",
    "Test['tweet'] = [ tweet.casefold() for tweet in Test['tweet'] ]\n",
    "Test['tweet'] = Test['tweet'].apply(lambda x: ' '.join([word for word in x.split() if word not in (stop)]))\n",
    "Test['tweet'] = Test['tweet'].apply(lambda x: ' '.join([porter.stem(word) for word in x.split()]))\n",
    "print(len(Data['Tweet']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-warning\">\n",
    "    2. Transform Training & Testing Data to vectors\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\khled\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:7: DeprecationWarning: Call to deprecated `wv` (Attribute will be removed in 4.0.0, use self instead).\n",
      "  import sys\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "300\n"
     ]
    }
   ],
   "source": [
    "#Transform tweets to array\n",
    "Tweets_wv = []\n",
    "for i in range(0,16041):\n",
    "    F = 1\n",
    "    Sentince = [0]*300\n",
    "    for x in Data['Tweet'][i].split():\n",
    "        found = x in model.wv\n",
    "        if found:\n",
    "            F += 1\n",
    "            Sentince = Sentince + model[x]\n",
    "    Sentince = [ e / F-1 for e in Sentince ]\n",
    "    Tweets_wv.append(Sentince)\n",
    "\n",
    "print(len(Tweets_wv[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\khled\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:6: DeprecationWarning: Call to deprecated `wv` (Attribute will be removed in 4.0.0, use self instead).\n",
      "  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "300\n"
     ]
    }
   ],
   "source": [
    "Test_wv = []\n",
    "for i in range(0,3096):\n",
    "    F = 1\n",
    "    Sentince = [0]*300\n",
    "    for x in Test['tweet'][i].split():\n",
    "        found = x in model.wv\n",
    "        if found:\n",
    "            F += 1\n",
    "            Sentince = Sentince + model[x]\n",
    "    Sentince = [ e / F-1 for e in Sentince ]\n",
    "    Test_wv.append(Sentince)\n",
    "\n",
    "print(len(Test_wv[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-warning\">\n",
    "    3. Normalizing the vectors\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "Scaler = MinMaxScaler()\n",
    "Tweets_wv = Scaler.fit_transform(Tweets_wv)\n",
    "Test_wv = Scaler.fit_transform(Test_wv)\n",
    "#print(Tweets_wv[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-warning\">\n",
    "    4. Testing\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy = 56.16925064599483%\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.00      0.00      0.00       460\n",
      "     neutral       0.55      0.77      0.64      1374\n",
      "    positive       0.58      0.54      0.56      1262\n",
      "\n",
      "   micro avg       0.56      0.56      0.56      3096\n",
      "   macro avg       0.38      0.44      0.40      3096\n",
      "weighted avg       0.48      0.56      0.51      3096\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\khled\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "#Na√Øve Bayes Multinomial\n",
    "Clf = naive_bayes.MultinomialNB()\n",
    "Clf.fit(Tweets_wv,Data['Label'])\n",
    "Pred = Clf.predict(Test_wv)\n",
    "acc = metrics.accuracy_score(test_labels['vlabels'],Pred)\n",
    "print ('accuracy = '+str(acc*100)+'%')\n",
    "print (metrics.classification_report(test_labels['vlabels'],Pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy = 54.78036175710594%\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.35      0.67      0.46       460\n",
      "     neutral       0.59      0.71      0.64      1374\n",
      "    positive       0.74      0.33      0.46      1262\n",
      "\n",
      "   micro avg       0.55      0.55      0.55      3096\n",
      "   macro avg       0.56      0.57      0.52      3096\n",
      "weighted avg       0.61      0.55      0.54      3096\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#SVM (Linear Kernel)\n",
    "Clf = svm.SVC(kernel='linear', C=1)\n",
    "Clf.fit(Tweets_wv,Data['Label'])\n",
    "Pred = Clf.predict(Test_wv)\n",
    "acc = metrics.accuracy_score(test_labels['vlabels'],Pred)\n",
    "print ('accuracy = '+str(acc*100)+'%')\n",
    "print (metrics.classification_report(test_labels['vlabels'],Pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\khled\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\khled\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:460: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
      "  \"this warning.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy = 57.428940568475454%\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.40      0.58      0.47       460\n",
      "     neutral       0.58      0.76      0.66      1374\n",
      "    positive       0.74      0.37      0.49      1262\n",
      "\n",
      "   micro avg       0.57      0.57      0.57      3096\n",
      "   macro avg       0.57      0.57      0.54      3096\n",
      "weighted avg       0.62      0.57      0.56      3096\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Logistic Regression\n",
    "Clf = LogisticRegression()\n",
    "Clf.fit(Tweets_wv,Data['Label'])\n",
    "Pred = Clf.predict(Test_wv)\n",
    "acc = metrics.accuracy_score(test_labels['vlabels'],Pred)\n",
    "print ('accuracy = '+str(acc*100)+'%')\n",
    "print (metrics.classification_report(test_labels['vlabels'],Pred))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
